{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('train.json', 'r') as f:\n",
    "    train_json = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('valid.json', 'r') as f:\n",
    "    valid_json = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('test.json', 'r') as f:\n",
    "    test_json = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = re.compile(\"(\\W|\\d)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# with open('corpus.txt', 'w') as f:\n",
    "#     for message in train_json:\n",
    "#         for m in message['messages-so-far']:\n",
    "#             f.write(\" \".join(pattern.split(str.lower(m['utterance']))))\n",
    "#             f.write('\\n')\n",
    "#         for o in message['options-for-next']:\n",
    "#             f.write(\" \".join(pattern.split(str.lower(o['utterance']))))\n",
    "#             f.write('\\n')\n",
    "#     for message in valid_json:\n",
    "#         for m in message['messages-so-far']:\n",
    "#             f.write(\" \".join(pattern.split(str.lower(m['utterance']))))\n",
    "#             f.write('\\n')\n",
    "#         for o in message['options-for-next']:\n",
    "#             f.write(\" \".join(pattern.split(str.lower(o['utterance']))))\n",
    "#             f.write('\\n')\n",
    "#     for message in test_json:\n",
    "#         for m in message['messages-so-far']:\n",
    "#             f.write(\" \".join(pattern.split(str.lower(m['utterance']))))\n",
    "#             f.write('\\n')\n",
    "#         for o in message['options-for-next']:\n",
    "#             f.write(\" \".join(pattern.split(str.lower(o['utterance']))))\n",
    "#             f.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'!',\n",
       " '\"',\n",
       " '#',\n",
       " '$',\n",
       " '%',\n",
       " '&',\n",
       " \"'\",\n",
       " '(',\n",
       " ')',\n",
       " '*',\n",
       " '+',\n",
       " ',',\n",
       " '-',\n",
       " '.',\n",
       " '/',\n",
       " ':',\n",
       " ';',\n",
       " '<',\n",
       " '=',\n",
       " '>',\n",
       " '?',\n",
       " '@',\n",
       " '[',\n",
       " '\\\\',\n",
       " ']',\n",
       " '^',\n",
       " '_',\n",
       " '`',\n",
       " '{',\n",
       " '|',\n",
       " '}',\n",
       " '~'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import string\n",
    "symbolset = set(string.punctuation)\n",
    "symbolset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2min 8s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "with open('corpus.txt', 'w') as f:\n",
    "    for message in train_json:\n",
    "        for m in message['messages-so-far']:\n",
    "            # Remove the symbols.\n",
    "            for symbol in symbolset:\n",
    "                m['utterance'] = m['utterance'].replace(symbol, ' ')\n",
    "            f.write(\" \".join(pattern.split(str.lower(m['utterance']))))\n",
    "            f.write('\\n')\n",
    "        for o in message['options-for-next']:\n",
    "            # Remove the symbols.\n",
    "            for symbol in symbolset:\n",
    "                o['utterance'] = o['utterance'].replace(symbol, ' ')\n",
    "            f.write(\" \".join(pattern.split(str.lower(o['utterance']))))\n",
    "            f.write('\\n')\n",
    "    for message in valid_json:\n",
    "        for m in message['messages-so-far']:\n",
    "            # Remove the symbols.\n",
    "            for symbol in symbolset:\n",
    "                m['utterance'] = m['utterance'].replace(symbol, ' ')\n",
    "            f.write(\" \".join(pattern.split(str.lower(m['utterance']))))\n",
    "            f.write('\\n')\n",
    "        for o in message['options-for-next']:\n",
    "            # Remove the symbols.\n",
    "            for symbol in symbolset:\n",
    "                o['utterance'] = o['utterance'].replace(symbol, ' ')\n",
    "            f.write(\" \".join(pattern.split(str.lower(o['utterance']))))\n",
    "            f.write('\\n')\n",
    "    for message in test_json:\n",
    "        for m in message['messages-so-far']:\n",
    "            # Remove the symbols.\n",
    "            for symbol in symbolset:\n",
    "                m['utterance'] = m['utterance'].replace(symbol, ' ')\n",
    "            f.write(\" \".join(pattern.split(str.lower(m['utterance']))))\n",
    "            f.write('\\n')\n",
    "        for o in message['options-for-next']:\n",
    "            # Remove the symbols.\n",
    "            for symbol in symbolset:\n",
    "                o['utterance'] = o['utterance'].replace(symbol, ' ')\n",
    "            f.write(\" \".join(pattern.split(str.lower(o['utterance']))))\n",
    "            f.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.word2vec import LineSentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = LineSentence(\"corpus.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "cpus = multiprocessing.cpu_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 6min 48s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model = Word2Vec(sentences, workers=cpus / 2, size=64, sg=0, window=1, min_count=0, sample=1e-3, seed=0)\n",
    "model.save('w2v')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('w2v.pkl', 'wb') as f:\n",
    "    pickle.dump(model, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
